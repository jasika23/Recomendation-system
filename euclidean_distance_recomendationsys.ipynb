{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d813b723",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b9b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c328a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d4c5f",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "## Random Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55c0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "[[0. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Testsize = 17678\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "train_df, test_df\n",
    "\n",
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "item_popularity = np.zeros(n_items)\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "    item_popularity[row[2]-1] =  item_popularity[row[2]-1] + 1\n",
    "#train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "testsize = 0\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    if item_popularity[row[2]-1] > 30:\n",
    "        test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "        testsize = testsize + 1\n",
    "#test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)\n",
    "\n",
    "print(\"Testsize = \" + str(testsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91d27b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b927f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you can use this devaluate Utils here, and you can also implement your own MAE and RMSE calculation. \n",
    "\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2f81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2c38f6-0909-45f1-a59c-7cc2bd087bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8406522030083707\n",
      "RMSE: 1.064624030504147\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# You are required to implement the required solution here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "#################################### ADJUSTED EUCLIDEAN DISTANCE ################\n",
    "# defining adjusted Euclidean Distance function\n",
    "def adjusted_euclidean_distance(user1, user2, V_max, V_min):\n",
    "    # common items rated by 2 users\n",
    "    common_items = np.where((user1 > 0) & (user2 > 0))[0]\n",
    "    # if there are no common items \n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Ratings for the common items\n",
    "    r_u_s = user1[common_items]\n",
    "    r_v_s = user2[common_items]\n",
    "    \n",
    "    # adjusted Euclidean distance using the formula given \n",
    "    numerator = np.sqrt(np.sum((r_u_s - r_v_s) ** 2))\n",
    "    denominator = np.sqrt(len(common_items) * (V_max - V_min) ** 2)\n",
    "    \n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "#  finding K nearest neighbors\n",
    "def find_k_nearest_neighbors(user_id, k, train_ds, V_max, V_min):\n",
    "    similarities = []\n",
    "    # Calculate adjusted Euclidean distance between the user and all other users\n",
    "    for other_user_id in range(train_ds.shape[0]):\n",
    "        if user_id != other_user_id:\n",
    "            sim = adjusted_euclidean_distance(train_ds[user_id], train_ds[other_user_id], V_max, V_min)\n",
    "            similarities.append((other_user_id, sim))\n",
    "    # Sort users based on similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:k]\n",
    "\n",
    "# Function to predict rating\n",
    "def predict_rating(user_id, item_id, k, train_ds, V_max, V_min):\n",
    "    neighbors = find_k_nearest_neighbors(user_id, k, train_ds, V_max, V_min)\n",
    "    total_sim = weighted_sum = 0\n",
    "    # if we get C_0 then we have perfect similarity\n",
    "    C_0 = [(neighbor_id, sim) for neighbor_id, sim in neighbors if sim == 1]\n",
    "    \n",
    "    if len(C_0) > 0:\n",
    "        # Calculate weighted sum for users who have rated the same items with identical ratings.\n",
    "        k_0 = 1 / sum([abs(sim) for _, sim in C_0])\n",
    "        for neighbor_id, sim in C_0:\n",
    "            if train_ds[neighbor_id, item_id] > 0:\n",
    "                weighted_sum += train_ds[neighbor_id, item_id] * k_0\n",
    "                total_sim += k_0\n",
    "    else:\n",
    "        # Calculate weighted sum for other neighbors\n",
    "        k = 1 / sum([abs(sim) for _, sim in neighbors])\n",
    "        for neighbor_id, sim in neighbors:\n",
    "            #If the neighbor has rated the item, their rating is multiplied by their similarity score\n",
    "            if train_ds[neighbor_id, item_id] > 0:\n",
    "                weighted_sum += train_ds[neighbor_id, item_id] * sim\n",
    "                # the absolute value of similarity score is then added to is added to total_sim \n",
    "                total_sim += abs(sim)\n",
    "    \n",
    "    # Calculate the user's mean rating\n",
    "    user_mean = np.mean(train_ds[user_id, np.where(train_ds[user_id] > 0)])\n",
    "    # Return predicted rating (average if total similarity is 0)\n",
    "    return user_mean if total_sim == 0 else weighted_sum / total_sim\n",
    "\n",
    "# Main collaborative filtering function\n",
    "def user_knn_cf(train_ds, test_ds, k, V_max, V_min):\n",
    "    \n",
    "    # Initialize an array to store the predicted ratings\n",
    "    predictions = np.zeros_like(test_ds)\n",
    "    \n",
    "    # Predict ratings for each user-item pair in the test dataset\n",
    "    for user_id in range(test_ds.shape[0]):\n",
    "        for item_id in range(test_ds.shape[1]):\n",
    "            # Check if the user has rated the item in the test dataset\n",
    "            if test_ds[user_id, item_id] > 0:\n",
    "                # Predict the rating for the user-item pair using the predict_rating function\n",
    "                predicted_rating = predict_rating(user_id, item_id, k, train_ds, V_max, V_min)\n",
    "                # Store the predicted rating in the predictions array\n",
    "                predictions[user_id, item_id] = predicted_rating\n",
    "    \n",
    "    # Return the array of predicted ratings\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Provided evaluate function\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    mask_test_ds = test_ds > 0\n",
    "    # Calculate Mean Absolute Error (MAE) and Root Mean Square Error (RMSE)\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "    return MAE, RMSE\n",
    "\n",
    "k = 3\n",
    "V_max = np.max(train_ds)\n",
    "V_min = np.min(train_ds)\n",
    "\n",
    "# Perform collaborative filtering using user-based k-NN with adjusted Euclidean distance\n",
    "predicted_ds = user_knn_cf(train_ds, test_ds, k, V_max, V_min)\n",
    "# Evaluate the performance of the model\n",
    "MAE, RMSE = evaluate(test_ds, predicted_ds)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'RMSE: {RMSE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e89b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.8406522030083707, RMSE: 1.064624030504147\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3325abe-6965-4165-a4cb-fecebbb46539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8524958864884756\n",
      "RMSE: 1.0844743305110824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################### Just to see how pearson correlation performs and to use in the presentation #######\n",
    "\n",
    "# we first start by defining the pearson correlation function \n",
    "\n",
    "def pearson_correlation(user1, user2):\n",
    "    # we then find the common items rated by 2 users \n",
    "    common_items = np.where((user1 > 0) & (user2 > 0))[0]\n",
    "    # if no common item between the users, then return 0 \n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "\n",
    "    # if there are common items then following loop \n",
    "    \n",
    "    # Rating for the common items from both the users are taken \n",
    "    user1_ratings = user1[common_items]\n",
    "    user2_ratings = user2[common_items]\n",
    "\n",
    "    # we calculate the means of the common items rated by the users\n",
    "    mean_user1 = np.mean(user1_ratings)\n",
    "    mean_user2 = np.mean(user2_ratings)\n",
    "\n",
    "    # numerator and denominator for Pearson correlation\n",
    "    numerator = np.sum((user1_ratings - mean_user1) * (user2_ratings - mean_user2))\n",
    "    denominator = np.sqrt(np.sum((user1_ratings - mean_user1) ** 2)) * np.sqrt(np.sum((user2_ratings - mean_user2) ** 2))\n",
    "    \n",
    "    # if denom = 0 then the frac is invalid so return 0 \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    return numerator / denominator\n",
    "\n",
    "# Define function to find K nearest neighbors\n",
    "def find_k_nearest_neighbors(user_id, k, train_ds):\n",
    "    similarities = []\n",
    "    # Calculate similarity the users and all the other users using pearson correlation\n",
    "    for other_user_id in range(train_ds.shape[0]):\n",
    "        if user_id != other_user_id:\n",
    "            sim = pearson_correlation(train_ds[user_id], train_ds[other_user_id])\n",
    "            similarities.append((other_user_id, sim))\n",
    "            \n",
    "    # Similarities are sorted in descending order\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top K most similar neighbors\n",
    "    return similarities[:k]\n",
    "\n",
    "# Define function to predict rating\n",
    "def predict_rating(user_id, item_id, k, train_ds):\n",
    "    \n",
    "    # Find K nearest neighbors for the user\n",
    "    neighbors = find_k_nearest_neighbors(user_id, k, train_ds)\n",
    "    total_sim = 0\n",
    "    weighted_sum = 0\n",
    "    # Iterate through neighbors\n",
    "    for neighbor_id, sim in neighbors:\n",
    "        # Check if the neighbor rated the item\n",
    "        if train_ds[neighbor_id, item_id] > 0:\n",
    "            # Add weighted rating to weighted_sum\n",
    "            weighted_sum += train_ds[neighbor_id, item_id] * sim\n",
    "            total_sim += abs(sim)\n",
    "    # Predict the rating for the item\n",
    "    if total_sim == 0:\n",
    "        # If no similar neighbors, return the mean rating of the user\n",
    "        return np.mean(train_ds[user_id, np.where(train_ds[user_id] > 0)])\n",
    "    return weighted_sum / total_sim\n",
    "\n",
    "# Define the main collaborative filtering function\n",
    "def user_knn_cf(train_ds, test_ds, k):\n",
    "    # Initialize an array to store predictions\n",
    "    predictions = np.zeros_like(test_ds)\n",
    "    # Iterate through each user in the test set\n",
    "    for user_id in range(test_ds.shape[0]):\n",
    "        # Iterate through each item for the user\n",
    "        for item_id in range(test_ds.shape[1]):\n",
    "            # Check if the user rated the item\n",
    "            if test_ds[user_id, item_id] > 0:\n",
    "                # Predict the rating for the item using KNN\n",
    "                predicted_rating = predict_rating(user_id, item_id, k, train_ds)\n",
    "                # Store the predicted rating in the predictions array\n",
    "                predictions[user_id, item_id] = predicted_rating\n",
    "    # Return the predictions\n",
    "    return predictions\n",
    "\n",
    "# Define the value of K (number of neighbors)\n",
    "k = 3\n",
    "\n",
    "# Generate predictions using the KNN collaborative filtering method\n",
    "predicted_ds = user_knn_cf(train_ds, test_ds, k)\n",
    "\n",
    "# Evaluate the predictions using the provided evaluation function\n",
    "MAE, RMSE = evaluate(test_ds, predicted_ds)\n",
    "\n",
    "# Print the results\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'RMSE: {RMSE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c11f62-42af-4bfc-8314-c7f60d6004d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
